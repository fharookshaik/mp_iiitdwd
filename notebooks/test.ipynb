{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path(r'D:\\fharookshaik\\Documents\\major_project\\dataset')\n",
    "TRAIN_CSV = os.path.join(DATASET_PATH,'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OCR</th>\n",
       "      <th>image</th>\n",
       "      <th>hero</th>\n",
       "      <th>villain</th>\n",
       "      <th>victim</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bernie or Elizabeth? Be informed.Compare them ...</td>\n",
       "      <td>covid_memes_18.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['bernie sanders', 'elizabeth warren']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extending the Brexit deadline until October 31...</td>\n",
       "      <td>covid_memes_19.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['uk government']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kwai gkwa 0964 #nnevvy applause to Thais from ...</td>\n",
       "      <td>covid_memes_252.png</td>\n",
       "      <td>['thais']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['hong kong']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So, I order this foce mask to protect ogainst ...</td>\n",
       "      <td>covid_memes_255.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['china']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['face mask', 'made in china', 'coronavirus']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best candidate for JA 2020 joe biden Kamala ha...</td>\n",
       "      <td>covid_memes_20.png</td>\n",
       "      <td>['joe biden']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['bernie sanders', 'kamala harris', 'tiktok']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 OCR                image  \\\n",
       "0  Bernie or Elizabeth? Be informed.Compare them ...   covid_memes_18.png   \n",
       "1  Extending the Brexit deadline until October 31...   covid_memes_19.png   \n",
       "2  kwai gkwa 0964 #nnevvy applause to Thais from ...  covid_memes_252.png   \n",
       "3  So, I order this foce mask to protect ogainst ...  covid_memes_255.png   \n",
       "4  best candidate for JA 2020 joe biden Kamala ha...   covid_memes_20.png   \n",
       "\n",
       "            hero            villain victim  \\\n",
       "0            NaN                NaN    NaN   \n",
       "1            NaN  ['uk government']    NaN   \n",
       "2      ['thais']                NaN    NaN   \n",
       "3            NaN          ['china']    NaN   \n",
       "4  ['joe biden']                NaN    NaN   \n",
       "\n",
       "                                           other  \n",
       "0         ['bernie sanders', 'elizabeth warren']  \n",
       "1                                            NaN  \n",
       "2                                  ['hong kong']  \n",
       "3  ['face mask', 'made in china', 'coronavirus']  \n",
       "4  ['bernie sanders', 'kamala harris', 'tiktok']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OCR</th>\n",
       "      <th>image</th>\n",
       "      <th>hero</th>\n",
       "      <th>villain</th>\n",
       "      <th>victim</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bernie or Elizabeth? Be informed.Compare them ...</td>\n",
       "      <td>covid_memes_18.png</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['bernie sanders', 'elizabeth warren']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extending the Brexit deadline until October 31...</td>\n",
       "      <td>covid_memes_19.png</td>\n",
       "      <td>[]</td>\n",
       "      <td>['uk government']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kwai gkwa 0964 #nnevvy applause to Thais from ...</td>\n",
       "      <td>covid_memes_252.png</td>\n",
       "      <td>['thais']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['hong kong']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So, I order this foce mask to protect ogainst ...</td>\n",
       "      <td>covid_memes_255.png</td>\n",
       "      <td>[]</td>\n",
       "      <td>['china']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['face mask', 'made in china', 'coronavirus']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best candidate for JA 2020 joe biden Kamala ha...</td>\n",
       "      <td>covid_memes_20.png</td>\n",
       "      <td>['joe biden']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['bernie sanders', 'kamala harris', 'tiktok']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>Trump could shoot someone on the Senate floor ...</td>\n",
       "      <td>memes_5039.png</td>\n",
       "      <td>[]</td>\n",
       "      <td>['donald trump']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['senate floor', 'republican']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>MANY PEOPLE ASK ME WHY ALL MY SCHOOL RECORDS A...</td>\n",
       "      <td>memes_2635.png</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['school', 'university', 'joe biden']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>my bes friend my mother consclence my therapis...</td>\n",
       "      <td>memes_1384.png</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['msnbc', 'bernie sanders', 'democratic party'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>THE N-WORD PASS Signed and approved by Beak Ob...</td>\n",
       "      <td>memes_944.png</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['barack obama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>Biden-Obama Memes 300. Funny &amp; Hillarious Meme...</td>\n",
       "      <td>memes_982.png</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['biden obama meme', 'john robinson', 'memes',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5552 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    OCR                image  \\\n",
       "0     Bernie or Elizabeth? Be informed.Compare them ...   covid_memes_18.png   \n",
       "1     Extending the Brexit deadline until October 31...   covid_memes_19.png   \n",
       "2     kwai gkwa 0964 #nnevvy applause to Thais from ...  covid_memes_252.png   \n",
       "3     So, I order this foce mask to protect ogainst ...  covid_memes_255.png   \n",
       "4     best candidate for JA 2020 joe biden Kamala ha...   covid_memes_20.png   \n",
       "...                                                 ...                  ...   \n",
       "5547  Trump could shoot someone on the Senate floor ...       memes_5039.png   \n",
       "5548  MANY PEOPLE ASK ME WHY ALL MY SCHOOL RECORDS A...       memes_2635.png   \n",
       "5549  my bes friend my mother consclence my therapis...       memes_1384.png   \n",
       "5550  THE N-WORD PASS Signed and approved by Beak Ob...        memes_944.png   \n",
       "5551  Biden-Obama Memes 300. Funny & Hillarious Meme...        memes_982.png   \n",
       "\n",
       "               hero            villain victim  \\\n",
       "0                []                 []     []   \n",
       "1                []  ['uk government']     []   \n",
       "2         ['thais']                 []     []   \n",
       "3                []          ['china']     []   \n",
       "4     ['joe biden']                 []     []   \n",
       "...             ...                ...    ...   \n",
       "5547             []   ['donald trump']     []   \n",
       "5548             []                 []     []   \n",
       "5549             []                 []     []   \n",
       "5550             []                 []     []   \n",
       "5551             []                 []     []   \n",
       "\n",
       "                                                  other  \n",
       "0                ['bernie sanders', 'elizabeth warren']  \n",
       "1                                                    []  \n",
       "2                                         ['hong kong']  \n",
       "3         ['face mask', 'made in china', 'coronavirus']  \n",
       "4         ['bernie sanders', 'kamala harris', 'tiktok']  \n",
       "...                                                 ...  \n",
       "5547                     ['senate floor', 'republican']  \n",
       "5548              ['school', 'university', 'joe biden']  \n",
       "5549  ['msnbc', 'bernie sanders', 'democratic party'...  \n",
       "5550                                   ['barack obama']  \n",
       "5551  ['biden obama meme', 'john robinson', 'memes',...  \n",
       "\n",
       "[5552 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning data\n",
    "train_df['OCR'] = train_df['OCR'].fillna(\"\")\n",
    "train_df['hero'] = train_df['hero'].fillna({i: [] for i in train_df.index})\n",
    "train_df['villain'] = train_df['villain'].fillna({i: [] for i in train_df.index})\n",
    "train_df['victim'] = train_df['victim'].fillna({i: [] for i in train_df.index})\n",
    "train_df['other'] = train_df['other'].fillna({i: [] for i in train_df.index})\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fharookshaik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\fharookshaik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def sentences_to_nouns(sentence):\n",
    "    # case normalization\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # Remove unwanted chracters\n",
    "    sentence = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", sentence)\n",
    "\n",
    "    # Remove Stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    sentence = \" \".join([word for word in sentence.split() if word not in (stop)])\n",
    "\n",
    "    # Tokenize sentence\n",
    "    list_tokns = sentence.split()\n",
    "\n",
    "    # Find nouns from sentence\n",
    "    pos = nltk.pos_tag(list_tokns)\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    # do the nlp stuff\n",
    "    nouns = [word for (word,pos) in nltk.pos_tag(list_tokns) if is_noun(pos)]\n",
    "\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = []\n",
    "for idx,val in train_df.iterrows():\n",
    "    entities.append(sentences_to_nouns(val.get('OCR')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bernie', 'elizabeth', 'issues', 'issue', 'memes']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35963"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for entity in entities:\n",
    "    sum += len(entity)\n",
    "\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10112"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_entities = []\n",
    "for entitylist in entities:\n",
    "    for entity in entitylist:\n",
    "        if entity not in unique_entities:\n",
    "            unique_entities.append(entity)\n",
    "\n",
    "len(unique_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enty_sent_dict = {}\n",
    "\n",
    "# for entity in enty_sent_dict:\n",
    "#     enty_sent_dict[entity] = []\n",
    "\n",
    "# for idx,val in train_df.iterrows():\n",
    "#     sentence = val.get('OCR').lower()\n",
    "#     sentence = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", sentence)\n",
    "#     for entity in entities:\n",
    "#         print(entity,sentence)\n",
    "#         if re.search(entity,sentence):\n",
    "#             enty_sent_dict[entity] = enty_sent_dict[entity].append(sentence)\n",
    "\n",
    "# enty_sent_dict      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3266/10112 [27:36<57:53,  1.97it/s]  \n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Find sentences according to entities\n",
    "enty_sent_dict = {}\n",
    "\n",
    "# for entity in enty_sent_dict:\n",
    "#     enty_sent_dict[entity] = []\n",
    "\n",
    "def find_enty_sent(entity):\n",
    "    temp_sent_list = []\n",
    "    for idx,val in train_df.iterrows():\n",
    "        sentence = val.get('OCR').lower()\n",
    "        sentence = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", sentence)\n",
    "        if re.search(entity,sentence):\n",
    "            temp_sent_list.append(sentence)\n",
    "    enty_sent_dict[entity] = temp_sent_list\n",
    "    return True\n",
    "\n",
    "def run():\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        result = list(tqdm(executor.map(find_enty_sent,unique_entities),total=len(unique_entities)))\n",
    "    return result\n",
    "    # for idx,res in enumerate(result):\n",
    "    #     print(f'{idx} : {res}')\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4c84cd834ebcb89cbc041855604078ba946dc10fdd4506446b733f5e3e5edb6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
